#!/usr/bin/env python
# coding: utf-8

# # Explora aqu√≠
# 
# Se recomienda utilizar este cuaderno con fines de exploraci√≥n.

# # üìôWeb Scraping Solution

# ## üü†Step 1: Install dependencies as per requirements file

# In[72]:


get_ipython().system('python -m pip install -r ../requirements.txt')


# In[73]:


#import os
#from bs4 import BeautifulSoup  # De la libreria bs4 (Nuevo nombere de la libreria) traeme la funcion BeautifulSoup
#import requests
#import time
#import pandas as pd
import sqlite3
import matplotlib.pyplot as plt
import seaborn as sns


# ## üü†Step 2: Download HTML
# The download of the HTML of the web page will be done with the requests library, as we saw in the module theory.
# 
# The web page we want to scrape is the following: https://ycharts.com/companies/TSLA/revenues. It collects and stores information about the growth of the company every three months, since June 2009. It stores the text scraped from the web in some variable.

# In[74]:


import os # Importo libreria necesaria

# Para evitar que la respuesta sea "403 Forbidden", intento con un User Anonimo. (If no information is extracted, then connect as anonymous).
# Para esto defino un User-Agent falso para que la solicitud parezca provenir de un navegador real, ya que
# los servidores bloquean a los bots, pero permiten navegadores con User-Agent v√°lidos.

headers = {"User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36"}

# EXPLICACION DEL USER-AGENT

# 1. headers
#     headers es una variable que contiene un diccionario. En este caso, se usa para definir un conjunto de cabeceras HTTP (headers) que se enviar√°n junto con la solicitud HTTP.

# 2. ¬øQu√© son los "headers" en una solicitud HTTP?
#     Headers (cabeceras) son informaci√≥n adicional que se env√≠a junto con una solicitud HTTP para proporcionar detalles sobre la solicitud o sobre el cliente que la est√° haciendo (por ejemplo, el navegador que est√°s usando).

# 3. El header User-Agent
#     En este caso, est√°s utilizando un header espec√≠fico llamado User-Agent.
#     El User-Agent le dice al servidor qu√© tipo de cliente est√° haciendo la solicitud (por ejemplo, qu√© navegador web est√° usando).

# 4. El valor del User-Agent
#     El valor de este User-Agent es:
#     "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36"
#     Este es un string largo que indica varias cosas sobre el navegador y el sistema operativo de la persona que est√° haciendo la solicitud. Aqu√≠ te desgloso cada parte:
#
#     Mozilla/5.0: 
#       Indica que el navegador es compatible con el est√°ndar Mozilla (aunque ahora muchos navegadores usan este mismo formato, como Chrome y Safari). Esto es hist√≥rico y es parte del proceso de compatibilidad entre navegadores.
#     (Macintosh; Intel Mac OS X 10_11_5): 
#       Indica que el cliente est√° utilizando un sistema operativo Mac OS X en una m√°quina con un procesador Intel.
#     AppleWebKit/537.36: 
#       Esto hace referencia al motor de renderizado que utiliza el navegador. AppleWebKit es el motor que usa Safari y Chrome.
#     (KHTML, like Gecko): 
#       Es una declaraci√≥n de compatibilidad con el motor de renderizado KHTML (usado en navegadores como Konqueror) y Gecko (usado en Firefox). Es una forma de asegurar que el servidor pueda interpretar correctamente las solicitudes de diferentes navegadores.
#     Chrome/50.0.2661.102: 
#       Informa que el navegador es Chrome versi√≥n 50.0.2661.102.
#     Safari/537.36: 
#       Esto indica que el navegador tambi√©n es compatible con Safari, versi√≥n 537.36.

# 5. ¬øPor qu√© usar un User-Agent falso?
#     Simular un navegador real: Algunos sitios web bloquean solicitudes autom√°ticas (como las de bots o scripts) si detectan que vienen de una fuente que no parece un navegador est√°ndar. Al configurar un User-Agent como el que has puesto, haces que tu solicitud parezca provenir de un navegador real (en este caso, un navegador Chrome en un Mac), lo que puede ayudar a evitar bloqueos por parte del servidor.

# 6. ¬øC√≥mo se usa en el c√≥digo?
#     Cuando usas este User-Agent en la solicitud, lo est√°s a√±adiendo a las cabeceras de la solicitud HTTP. As√≠, el servidor recibir√° la solicitud con el mismo User-Agent que usar√≠a un navegador real:
#       response = requests.get(url, headers=headers)
#     Aqu√≠ est√°s enviando el User-Agent dentro de las cabeceras HTTP de la solicitud, lo que hace que la solicitud parezca m√°s leg√≠tima y dif√≠cil de bloquear.

# 7. En resumen:
#    El User-Agent es una cadena de texto que identifica el navegador y el sistema operativo que est√° haciendo la solicitud. Usarlo en las cabeceras de una solicitud HTTP puede hacer que el servidor piense que la solicitud proviene de un navegador real, lo que puede ayudarte a evitar bloqueos al hacer web scraping o solicitudes autom√°ticas a ciertos sitios.


# In[75]:


# Importo librerias necesarias:
import requests # Generalmente no usamos alias
import time # Generalmente no usamos alias

url = "https://www.macrotrends.net/stocks/charts/TSLA/tesla/revenue" # Defino la url de la que voy a extraer informacion
response = requests.get(url, headers=headers) # Hace una nueva solicitud a la url definida, con el User-Agent para intentar evitar el bloqueo.
time.sleep(10) # Pausa el c√≥digo por 10 segundos, posiblemente para evitar ser detectado como bot.
response # Verifico si la respuestra a la solicitud http es valida (Por ejemplo, 200 en vez de 403).


# In[76]:


# Guardo el codigo en un csv para analizarlo en caso de necesitar.
if response: # Si existe codigo
    with open ("codigo_tesla.csv","wb") as file: 
        file.write(response.content)


# with open es la funcion para guardado. Entre parentesis ponemos la ruta donde guardar el 
    # archivo y el nombre que le daremos.
    # luego de la coma, le indicamos el metodo de escritura o apertura. (wb = write binary)
    # En este caso es escritura.
    # luego le decimos el alias
    # Es decir, con la funcion with open podemos abrir un archivo para lo que uno necesite, ya sea
    # lectura o escritura. 
    # El with nos asegura de que el archivo una vez que se abre, se cierre. Si pongo solo el open, 
    # luego tendremos que hacer el close. 
    # Veremos que dentro de la carpeta data / raw se abra generado el archivo csv (coma separeted values).
    
    # "w": Escritura (write mode), abre el archivo para escribir en el. Si el archivo ya existe, se sobrescribira. Si no existe, se creara.
    # "b": Modo Binario (binary mode), se puede combinar con otros modos ("rb, "wb", "ab") para trabajar con archivos binarios.


# In[77]:


html_data = response.text # Guarda el HTML en html_data
html_data # Muestro el HTML obtenido para verificar que se este logrando el cometido


# ## üü†Step 3: Transform the HTML
# The next step to start extracting the information is to transform it into a structured object. Do this using BeautifulSoup. Once you have interpreted the HTML correctly, parse it to:
# 
# 1. Find all the tables.
# 2. Find the table with the quarterly evolution.
# 3. Store the data in a DataFrame.
# 

# In[78]:


# Transform the extraction into a structured object using BeautifulSoup

from bs4 import BeautifulSoup # De la libreria bs4 (Nuevo nombere de la libreria) traeme la funcion BeautifulSoup

soup = BeautifulSoup(html_data,"html.parser") # usa la librer√≠a BeautifulSoup para analizar el c√≥digo HTML y convertirlo en un objeto que puedes manipular f√°cilmente con Python.
soup


# ### üß©3.1 Find all the tables

# In[79]:


# Find all tables
tables = soup.find_all("table") # soup es un objeto de BeautifulSoup que contiene el HTML de la p√°gina. find_all("table") busca y devuelve todas las etiquetas <table> dentro del HTML. El resultado es un ResultSet, que es una lista de elementos BeautifulSoup. 
tables # tables es entonces una lista de objetos BeautifulSoup, cada uno representando una tabla del HTML. Esto indica que tables contiene todas las tablas encontradas en el HTML.

# üíõ OTROS EJEMPLOS DE COMO USAR LOS DATOS EXTRAIDOS üíõ:
# soup.find_all("table")            : Encuentra todas las tablas en el HTML
# tables[0]                         : Obtiene la primera tabla de la lista
# tables[0].get_text()	            : Extrae solo el texto de la primera tabla
# pd.read_html(str(tables[0]))[0]   : Convierte la primera tabla en un DataFrame, importando previamente la libreria pandas

# üíõ ESTRUCTURA DE LAS TABLAS EN EL CODIGO üíõ:
# <th> = headers de la tabla
# <tr> = Rows de la tabla 
# <Caption> = Titulo de la tabla
# <td> = Celda de la tabla
# Por ahora vemos que la info es legible. 
# Tener en cuenta que todo lo que trae lo interpreta en formato texto, 
# asi que los numeros como % los tendremos que convertir a su formato Correcto.


# In[80]:


# üíõ TIP IMPORTANTE! üíõ:
# Esta buena copiar esto a un editor como notepad+, 
# para identificar ahi los distintos elementos de las tablas, la cantidad de tablas, etc.
# Si luego pego desde el notepad+ a excel, ya me muestra las tablas con formato, para visualizarlas mejor aun.


# ### üß©3.2 Find the table with the quarterly evolution

# In[81]:


# üß© Paso 1: 
# Importa la librer√≠a Pandas, que es clave para manipular y analizar datos en Python.
import pandas as pd  


# üß© Paso 2:
# Encontrar la tabla correcta
for index, table in enumerate(tables):
    if ("Tesla Quarterly Revenue" in str(table)):
        table_index = index
        break
table_index

# Explicacion:
    # tables es la lista de tablas extra√≠das (con beautifulsoup) de la url definida, 
    # Se recorre tables con enumerate(), que da dos valores:
    #     1. index: la posici√≥n de la tabla en la lista.
    #     2. table: la tabla en s√≠.

    # Se convierte cada table en texto con str(table).
    # Se busca una tabla que contenga la frase "Tesla Quarterly Revenue".
    # Cuando la encuentra, guarda su √≠ndice en table_index y detiene el bucle con break.


# ### üß©3.3 Store the data in a DataFrame.

# In[82]:


# üß© Paso 1: 
# Crear un DataFrame vac√≠o con dos columnas: "Date" y "Revenue", donde se guardar√°n los datos extra√≠dos.
df_tesla_revenue = pd.DataFrame(columns = ["Date", "Revenue"])


# üß© Paso 2: 
# Extraer datos de la tabla
for row in tables[table_index].tbody.find_all("tr"):
    col = row.find_all("td")
    if (col != []):
        Date = col[0].text
        Revenue = col[1].text #.replace("$", "").replace(",", "")
        df_tesla_revenue = pd.concat([df_tesla_revenue, pd.DataFrame({
            "Date": Date,
            "Revenue": Revenue
        }, index = [0])], ignore_index = True)

# Explicacion:
#  (1) Recorre todas las filas (tr) dentro del tbody de la tabla seleccionada (tables[table_index]).
#  (2) Para cada fila (row), encuentra las celdas (td) con find_all("td").
#  (3) Si col no est√° vac√≠o (col != []):
#       (*)Extrae la fecha (Date) de la primera celda (col[0].text).
#       (*)Extrae el revenue (Revenue) de la segunda celda (col[1].text), quitando "$" y "," con .replace().

#  (4) Agrega los datos al DataFrame usando pd.concat(), creando una nueva 
#      fila como DataFrame y uni√©ndola a tesla_revenue.

#  (5) ignore_index=True evita problemas con los √≠ndices.


# üß© Paso 3: 
# Mostrar los primeros datos
df_tesla_revenue.head()


# üß© Resumen Final:
#     (1) Busca la tabla correcta dentro de una lista de tablas.
#     (2) Crea un DataFrame vac√≠o con columnas Date y Revenue.
#     (3) Extrae las filas de la tabla y limpia los valores.
#     (4) Agrega las filas al DataFrame.
#     (5) Muestra los primeros resultados.


# ## üü†Step 4: Process the DataFrame
# Next, clean up the rows to get clean values by removing $ and commas. Remove also those that are empty or have no information.

# In[83]:


df_tesla_revenue.info()


# In[84]:


df_tesla_revenue = df_tesla_revenue[df_tesla_revenue["Revenue"] != ""]
df_tesla_revenue.head()



# In[85]:


df_tesla_revenue["Revenue"] = df_tesla_revenue["Revenue"].apply(lambda text: text.replace("$", "").replace(",", ""))
df_tesla_revenue["Revenue"] = pd.to_numeric(df_tesla_revenue["Revenue"])
df_tesla_revenue.head()

#  Explicaci√≥n:
#   (*) .apply(lambda text: text.replace("$", "").replace(",", ""))
#         Aplica .replace("$", "") y .replace(",", "") a cada fila de "Revenue".
#   (*) pd.to_numeric()
#         Convierte la columna a formato num√©rico (int o float).


# In[86]:


df_tesla_revenue.info()


# ## üü†Step 5: Store the data in sqlite
# 
# Create an empty instance of the database and include the clean data in it, as we saw in the database module. Once you have an empty database:
# 
#     Create the table.
#     Insert the values.
#     Store (commit) the changes.
# 

# In[87]:


import sqlite3

connection = sqlite3.connect("Tesla.db")
connection

# Crea una conexi√≥n a una base de datos SQLite llamada Tesla.db.
# Si el archivo Tesla.db no existe, SQLite lo crear√° autom√°ticamente 
# en el directorio donde est√°s ejecutando el c√≥digo.


# In[88]:


# 1. üß© Create the table.

cursor = connection.cursor()
cursor.execute("DROP TABLE IF EXISTS revenue")  # Elimina la tabla si ya existe
cursor.execute("""CREATE TABLE revenue (Date, Revenue)""")

# Se crea un cursor que te permite ejecutar comandos SQL en la base de datos.
#       cursor.execute("""CREATE TABLE revenue (Date, Revenue)""")

# Esta sentencia SQL crea una nueva tabla llamada revenue con dos columnas: 
# Date y Revenue.
# Sin embargo, no especificas los tipos de datos para estas columnas. 
# Si no defines los tipos de datos, SQLite los asignar√° autom√°ticamente. 
# Para ser m√°s preciso y evitar problemas futuros, puedes definir los tipos de datos expl√≠citamente.


# In[89]:


tesla_tuples = list(df_tesla_revenue.to_records(index = False))
tesla_tuples = [(record["Date"], str(record["Revenue"])) for record in tesla_tuples]
tesla_tuples[:5]  # muestra los primeros 5 elementos de la lista tesla_tuples.

#Explicaci√≥n:
#   (*) tesla_revenue.to_records(index=False):
#           to_records() convierte el DataFrame tesla_revenue a un array de registros (tuplas).
#           index=False asegura que el √≠ndice del DataFrame no se incluye en las tuplas resultantes.

#       El resultado es una lista de tuplas, donde cada tupla corresponde a una fila del DataFrame, 
#       y los valores de las columnas se almacenan en el orden correspondiente.

#   (*) list(...):
#            Convierte el array de registros a una lista de tuplas.

#   (*) [(record[..) for records in tesla_tuples] for record in tesla_tuples]:
#            toma los registros y convi√©rtelos a una lista de tuplas


# In[90]:


# 2. üß© Inset de Values
# 3. üß© Store (commit) the changes.

cursor.executemany("INSERT INTO revenue VALUES (?,?)", tesla_tuples)
connection.commit()


# In[91]:


# Check the data from the database
for row in cursor.execute("SELECT * FROM revenue"):
    print(row)


# ## üü†Step 6: Visualize the data
# What types of visualizations can we make? Suggest at least 3 and plot them.

# ### üß© Time Series

# In[92]:


# üìåImportaci√≥n de librer√≠as
import matplotlib.pyplot as plt # Se usa para crear gr√°ficos en Python.
import seaborn as sns # seaborn: Biblioteca basada en Matplotlib que facilita la visualizaci√≥n de datos.


# üìåCrear la figura y ejes
fig, axis = plt.subplots(figsize = (10, 5))
#    (-) plt.subplots(figsize=(10,5)): Crea una figura (fig) y un conjunto de ejes (axis).
#    (-) figsize=(10,5): Define el tama√±o de la figura (10 pulgadas de ancho y 5 de alto).


# üìåConvertir los datos a tipos adecuados
df_tesla_revenue["Date"] = pd.to_datetime(df_tesla_revenue["Date"]) # Convierte la columna Date en formato datetime (necesario para gr√°ficos de series de tiempo).
df_tesla_revenue["Revenue"] = df_tesla_revenue["Revenue"].astype('int') # Convierte la columna Revenue a tipo entero (por si ten√≠a otro tipo de dato como str).


# üìåCrear la l√≠nea de tiempo
sns.lineplot(data = df_tesla_revenue, x = "Date", y = "Revenue")
#   (-) sns.lineplot(): Crea un gr√°fico de l√≠neas con los datos de df_tesla_revenue.
#   (-) data = df_tesla_revenue: Especifica el DataFrame a usar.
#   (-) x = "Date": Eje X (fechas).
#   (-) y = "Revenue": Eje Y (ingresos).


# üìåAjustar el dise√±o del gr√°fico
plt.tight_layout() # Ajusta autom√°ticamente los m√°rgenes para que no haya solapamientos.

# üìåMostrar el gr√°fico
plt.show() # Muestra el gr√°fico generado.


# üìåEn resumen, este codigo dibuja un gr√°fico de l√≠neas donde:
#    (-) El eje X representa la fecha (Date).
#    (-) El eje Y representa los ingresos (Revenue).
#    (-) Se visualiza c√≥mo han cambiado los ingresos de Tesla a lo largo del tiempo.


# ### üß© Anual Gross Benefit 

# In[111]:


fig, axis = plt.subplots(figsize = (10, 5)) 
    # Crea la figura y el eje para el gr√°fico. 
    # figsize=(10, 5): Define el tama√±o del gr√°fico.

df_tesla_revenue["Date"] = pd.to_datetime(df_tesla_revenue["Date"]) 
    #Convierte la columna "Date" a formato datetime.
    #Esto permite hacer operaciones de tiempo como agrupar por a√±o.

df_tesla_revenue_yearly = df_tesla_revenue.groupby(df_tesla_revenue["Date"].dt.year)[["Revenue"]].sum().reset_index()
    # Agrupa los datos por a√±o (df_tesla_revenue["Date"].dt.year).
    # Aplica .sum() para sumar los valores dentro de cada a√±o.
    # [["Revenue"]]: Especifica que solo la columna "Revenue" debe sumarse, ignorando "Date".
    
sns.barplot(data = df_tesla_revenue_yearly[df_tesla_revenue_yearly["Date"] < 2023], x = "Date", y = "Revenue", palette= "viridis")
    # Filtra los datos para excluir los a√±os 2023 en adelante.
    # Crea un gr√°fico de barras con Seaborn.
    # pallete = "viridis" ‚Üí Esto le asignar√° un color diferente a cada barra seg√∫n la paleta "viridis".
            # Otras opciones: "coolwarm", "Blues", "Set2", etc.


# Ajusta los m√°rgenes del gr√°fico y lo muestra:
plt.tight_layout()
plt.show()



# ### üß©Monthly gross benefit

# In[115]:


fig, axis = plt.subplots(figsize = (10, 5))
    # Crea la figura (fig) y el eje (axis) para el gr√°fico.
    # figsize=(10, 5): Define el tama√±o del gr√°fico en pulgadas

df_tesla_revenue_monthly = df_tesla_revenue.groupby(df_tesla_revenue["Date"].dt.month)[["Revenue"]].sum().reset_index()
    #  df_tesla_revenue["Date"].dt.month ‚Üí Extrae el n√∫mero de mes de cada fecha.
    # .groupby(...) ‚Üí Agrupa los datos por mes.
    # [["Revenue"]].sum() ‚Üí Suma los ingresos (Revenue) de cada mes.
    # .reset_index() ‚Üí Convierte el resultado en un DataFrame ordenado.
        # Aqu√≠ "Date" representa el n√∫mero del mes (1 = enero, 2 = febrero, etc.).
                # Date    Revenue
                # 1	        50000
                # 2	        48000
                # 3	        52000
                # ...	      ...
                # 12	    60000


sns.barplot(data = df_tesla_revenue_monthly, x = "Date", y = "Revenue", palette= "viridis")
    # Crea un gr√°fico de barras con Seaborn.
    # x = "Date" ‚Üí Ubica los meses en el eje X.
    # y = "Revenue" ‚Üí Muestra los ingresos mensuales en el eje Y.
    # pallete = "viridis" ‚Üí Esto le asignar√° un color diferente a cada barra seg√∫n la paleta "viridis".
            # Otras opciones: "Blues", "Set2", etc.
            # Si quieres cambiar el orden de colores o hacer degradados, puedes probar: "coolwarm", "Spectral", "Set3"


plt.tight_layout() # ‚Üí Ajusta autom√°ticamente el dise√±o para evitar solapamientos.

plt.show() # ‚Üí Muestra el gr√°fico.

